{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43999b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd9bf90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 31 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   name                        100 non-null    int64  \n",
      " 1   baseline_wer                100 non-null    float64\n",
      " 2   baseline_cer                100 non-null    float64\n",
      " 3   baseline_pmr                100 non-null    float64\n",
      " 4   baseline_bleu               100 non-null    float64\n",
      " 5   baseline_cosine             100 non-null    float64\n",
      " 6   baseline_indobert           100 non-null    object \n",
      " 7   final_symspell_wer          100 non-null    float64\n",
      " 8   final_symspell_cer          100 non-null    float64\n",
      " 9   final_symspell_pmr          100 non-null    float64\n",
      " 10  final_symspell_bleu         100 non-null    float64\n",
      " 11  final_symspell_cosine       100 non-null    float64\n",
      " 12  final_symspell_indobert     100 non-null    object \n",
      " 13  final_llm_wer               100 non-null    float64\n",
      " 14  final_llm_cer               100 non-null    float64\n",
      " 15  final_llm_pmr               100 non-null    float64\n",
      " 16  final_llm_bleu              100 non-null    float64\n",
      " 17  final_llm_cosine            100 non-null    float64\n",
      " 18  final_llm_indobert          100 non-null    object \n",
      " 19  baseline_indobert_P         100 non-null    float64\n",
      " 20  baseline_indobert_R         100 non-null    float64\n",
      " 21  baseline_indobert_F1        100 non-null    float64\n",
      " 22  final_symspell_indobert_P   100 non-null    float64\n",
      " 23  final_symspell_indobert_R   100 non-null    float64\n",
      " 24  final_symspell_indobert_F1  100 non-null    float64\n",
      " 25  final_llm_indobert_P        100 non-null    float64\n",
      " 26  final_llm_indobert_R        100 non-null    float64\n",
      " 27  final_llm_indobert_F1       100 non-null    float64\n",
      " 28  baseline_jw                 100 non-null    float64\n",
      " 29  final_symspell_jw           100 non-null    float64\n",
      " 30  final_llm_jw                100 non-null    float64\n",
      "dtypes: float64(27), int64(1), object(3)\n",
      "memory usage: 24.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('final_with_indobert_jw.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b7d409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shapiro_wilk(data):\n",
    "    stat, p = stats.shapiro(data)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5efc08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_better = [\"wer\", \"cer\"]\n",
    "higher_better = [\"pmr\", \"bleu\", \"cosine\", \"jw\",\n",
    "                 \"indobert_P\", \"indobert_R\", \"indobert_F1\"]\n",
    "metrics = lower_better + higher_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eba9c8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(df, metric, method):\n",
    "    baseline = df[f\"baseline_{metric}\"].values\n",
    "    refined = df[f\"final_{method}_{metric}\"].values\n",
    "\n",
    "    if metric in lower_better: diff = baseline - refined  # positive = improvement\n",
    "    else: diff = refined - baseline  # positive = improvement\n",
    "\n",
    "    p_shapiro = shapiro_wilk(diff)\n",
    "    if p_shapiro >= 0.05:\n",
    "        stat, p_value = stats.ttest_rel(refined, baseline)\n",
    "        test_used = \"Paired t-test\"\n",
    "    else:\n",
    "        stat, p_value = wilcoxon(diff)\n",
    "        test_used = \"Wilcoxon signed-rank\"\n",
    "\n",
    "    return {\n",
    "        \"metric\": metric,\n",
    "        \"comparison\": f\"baseline vs {method}\",\n",
    "        \"test\": test_used,\n",
    "        \"shapiro_p\": p_shapiro,\n",
    "        \"p_value\": p_value,\n",
    "        \"mean_baseline\": np.mean(baseline),\n",
    "        \"mean_refined\": np.mean(refined),\n",
    "        \"mean_improvement\": np.mean(diff)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dee86a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>comparison</th>\n",
       "      <th>test</th>\n",
       "      <th>shapiro_p</th>\n",
       "      <th>p_value</th>\n",
       "      <th>mean_baseline</th>\n",
       "      <th>mean_refined</th>\n",
       "      <th>mean_improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wer</td>\n",
       "      <td>baseline vs symspell</td>\n",
       "      <td>Wilcoxon signed-rank</td>\n",
       "      <td>1.830843e-21</td>\n",
       "      <td>1.189345e-08</td>\n",
       "      <td>0.432745</td>\n",
       "      <td>0.172637</td>\n",
       "      <td>0.260108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wer</td>\n",
       "      <td>baseline vs llm</td>\n",
       "      <td>Wilcoxon signed-rank</td>\n",
       "      <td>1.805606e-21</td>\n",
       "      <td>6.946896e-11</td>\n",
       "      <td>0.432745</td>\n",
       "      <td>0.168569</td>\n",
       "      <td>0.264176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cer</td>\n",
       "      <td>baseline vs symspell</td>\n",
       "      <td>Wilcoxon signed-rank</td>\n",
       "      <td>2.971047e-21</td>\n",
       "      <td>7.169704e-09</td>\n",
       "      <td>0.319161</td>\n",
       "      <td>0.121424</td>\n",
       "      <td>0.197737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cer</td>\n",
       "      <td>baseline vs llm</td>\n",
       "      <td>Wilcoxon signed-rank</td>\n",
       "      <td>2.958096e-21</td>\n",
       "      <td>9.756623e-10</td>\n",
       "      <td>0.319161</td>\n",
       "      <td>0.120471</td>\n",
       "      <td>0.198690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pmr</td>\n",
       "      <td>baseline vs symspell</td>\n",
       "      <td>Wilcoxon signed-rank</td>\n",
       "      <td>2.205307e-12</td>\n",
       "      <td>1.591306e-06</td>\n",
       "      <td>0.172997</td>\n",
       "      <td>0.391989</td>\n",
       "      <td>0.218992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pmr</td>\n",
       "      <td>baseline vs llm</td>\n",
       "      <td>Wilcoxon signed-rank</td>\n",
       "      <td>4.471238e-11</td>\n",
       "      <td>5.129928e-07</td>\n",
       "      <td>0.172997</td>\n",
       "      <td>0.398404</td>\n",
       "      <td>0.225407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bleu</td>\n",
       "      <td>baseline vs symspell</td>\n",
       "      <td>Wilcoxon signed-rank</td>\n",
       "      <td>1.098987e-15</td>\n",
       "      <td>4.389483e-04</td>\n",
       "      <td>0.796237</td>\n",
       "      <td>0.804493</td>\n",
       "      <td>0.008257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bleu</td>\n",
       "      <td>baseline vs llm</td>\n",
       "      <td>Wilcoxon signed-rank</td>\n",
       "      <td>5.554253e-16</td>\n",
       "      <td>2.271705e-07</td>\n",
       "      <td>0.796237</td>\n",
       "      <td>0.813179</td>\n",
       "      <td>0.016942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cosine</td>\n",
       "      <td>baseline vs symspell</td>\n",
       "      <td>Wilcoxon signed-rank</td>\n",
       "      <td>1.065112e-17</td>\n",
       "      <td>5.249423e-03</td>\n",
       "      <td>0.883098</td>\n",
       "      <td>0.863786</td>\n",
       "      <td>-0.019312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cosine</td>\n",
       "      <td>baseline vs llm</td>\n",
       "      <td>Wilcoxon signed-rank</td>\n",
       "      <td>6.374799e-18</td>\n",
       "      <td>1.088094e-07</td>\n",
       "      <td>0.883098</td>\n",
       "      <td>0.876732</td>\n",
       "      <td>-0.006367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>jw</td>\n",
       "      <td>baseline vs symspell</td>\n",
       "      <td>Wilcoxon signed-rank</td>\n",
       "      <td>1.181378e-09</td>\n",
       "      <td>8.345072e-07</td>\n",
       "      <td>0.846417</td>\n",
       "      <td>0.879365</td>\n",
       "      <td>0.032948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>jw</td>\n",
       "      <td>baseline vs llm</td>\n",
       "      <td>Wilcoxon signed-rank</td>\n",
       "      <td>2.050876e-08</td>\n",
       "      <td>4.018257e-07</td>\n",
       "      <td>0.846417</td>\n",
       "      <td>0.883714</td>\n",
       "      <td>0.037298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>indobert_P</td>\n",
       "      <td>baseline vs symspell</td>\n",
       "      <td>Wilcoxon signed-rank</td>\n",
       "      <td>2.554037e-14</td>\n",
       "      <td>7.958557e-08</td>\n",
       "      <td>0.918677</td>\n",
       "      <td>0.935379</td>\n",
       "      <td>0.016702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>indobert_P</td>\n",
       "      <td>baseline vs llm</td>\n",
       "      <td>Wilcoxon signed-rank</td>\n",
       "      <td>2.391139e-14</td>\n",
       "      <td>8.032375e-10</td>\n",
       "      <td>0.918677</td>\n",
       "      <td>0.939799</td>\n",
       "      <td>0.021122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>indobert_R</td>\n",
       "      <td>baseline vs symspell</td>\n",
       "      <td>Wilcoxon signed-rank</td>\n",
       "      <td>1.570122e-16</td>\n",
       "      <td>1.806552e-03</td>\n",
       "      <td>0.937881</td>\n",
       "      <td>0.931343</td>\n",
       "      <td>-0.006538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>indobert_R</td>\n",
       "      <td>baseline vs llm</td>\n",
       "      <td>Wilcoxon signed-rank</td>\n",
       "      <td>1.519197e-16</td>\n",
       "      <td>4.356599e-06</td>\n",
       "      <td>0.937881</td>\n",
       "      <td>0.934322</td>\n",
       "      <td>-0.003559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>indobert_F1</td>\n",
       "      <td>baseline vs symspell</td>\n",
       "      <td>Wilcoxon signed-rank</td>\n",
       "      <td>9.618179e-16</td>\n",
       "      <td>6.827915e-06</td>\n",
       "      <td>0.927779</td>\n",
       "      <td>0.932791</td>\n",
       "      <td>0.005012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>indobert_F1</td>\n",
       "      <td>baseline vs llm</td>\n",
       "      <td>Wilcoxon signed-rank</td>\n",
       "      <td>9.299403e-16</td>\n",
       "      <td>1.488177e-08</td>\n",
       "      <td>0.927779</td>\n",
       "      <td>0.936471</td>\n",
       "      <td>0.008692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         metric            comparison                  test     shapiro_p  \\\n",
       "0           wer  baseline vs symspell  Wilcoxon signed-rank  1.830843e-21   \n",
       "1           wer       baseline vs llm  Wilcoxon signed-rank  1.805606e-21   \n",
       "2           cer  baseline vs symspell  Wilcoxon signed-rank  2.971047e-21   \n",
       "3           cer       baseline vs llm  Wilcoxon signed-rank  2.958096e-21   \n",
       "4           pmr  baseline vs symspell  Wilcoxon signed-rank  2.205307e-12   \n",
       "5           pmr       baseline vs llm  Wilcoxon signed-rank  4.471238e-11   \n",
       "6          bleu  baseline vs symspell  Wilcoxon signed-rank  1.098987e-15   \n",
       "7          bleu       baseline vs llm  Wilcoxon signed-rank  5.554253e-16   \n",
       "8        cosine  baseline vs symspell  Wilcoxon signed-rank  1.065112e-17   \n",
       "9        cosine       baseline vs llm  Wilcoxon signed-rank  6.374799e-18   \n",
       "10           jw  baseline vs symspell  Wilcoxon signed-rank  1.181378e-09   \n",
       "11           jw       baseline vs llm  Wilcoxon signed-rank  2.050876e-08   \n",
       "12   indobert_P  baseline vs symspell  Wilcoxon signed-rank  2.554037e-14   \n",
       "13   indobert_P       baseline vs llm  Wilcoxon signed-rank  2.391139e-14   \n",
       "14   indobert_R  baseline vs symspell  Wilcoxon signed-rank  1.570122e-16   \n",
       "15   indobert_R       baseline vs llm  Wilcoxon signed-rank  1.519197e-16   \n",
       "16  indobert_F1  baseline vs symspell  Wilcoxon signed-rank  9.618179e-16   \n",
       "17  indobert_F1       baseline vs llm  Wilcoxon signed-rank  9.299403e-16   \n",
       "\n",
       "         p_value  mean_baseline  mean_refined  mean_improvement  \n",
       "0   1.189345e-08       0.432745      0.172637          0.260108  \n",
       "1   6.946896e-11       0.432745      0.168569          0.264176  \n",
       "2   7.169704e-09       0.319161      0.121424          0.197737  \n",
       "3   9.756623e-10       0.319161      0.120471          0.198690  \n",
       "4   1.591306e-06       0.172997      0.391989          0.218992  \n",
       "5   5.129928e-07       0.172997      0.398404          0.225407  \n",
       "6   4.389483e-04       0.796237      0.804493          0.008257  \n",
       "7   2.271705e-07       0.796237      0.813179          0.016942  \n",
       "8   5.249423e-03       0.883098      0.863786         -0.019312  \n",
       "9   1.088094e-07       0.883098      0.876732         -0.006367  \n",
       "10  8.345072e-07       0.846417      0.879365          0.032948  \n",
       "11  4.018257e-07       0.846417      0.883714          0.037298  \n",
       "12  7.958557e-08       0.918677      0.935379          0.016702  \n",
       "13  8.032375e-10       0.918677      0.939799          0.021122  \n",
       "14  1.806552e-03       0.937881      0.931343         -0.006538  \n",
       "15  4.356599e-06       0.937881      0.934322         -0.003559  \n",
       "16  6.827915e-06       0.927779      0.932791          0.005012  \n",
       "17  1.488177e-08       0.927779      0.936471          0.008692  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for metric in metrics:\n",
    "    results.append(evaluate(df, metric, \"symspell\"))\n",
    "    results.append(evaluate(df, metric, \"llm\"))\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7f78139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>comparison</th>\n",
       "      <th>test</th>\n",
       "      <th>shapiro_p</th>\n",
       "      <th>p_value</th>\n",
       "      <th>mean_baseline</th>\n",
       "      <th>mean_refined</th>\n",
       "      <th>mean_improvement</th>\n",
       "      <th>p_corrected</th>\n",
       "      <th>significant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wer</td>\n",
       "      <td>baseline vs symspell</td>\n",
       "      <td>Wilcoxon signed-rank</td>\n",
       "      <td>1.830843e-21</td>\n",
       "      <td>1.189345e-08</td>\n",
       "      <td>0.432745</td>\n",
       "      <td>0.172637</td>\n",
       "      <td>0.260108</td>\n",
       "      <td>1.665083e-07</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cer</td>\n",
       "      <td>baseline vs symspell</td>\n",
       "      <td>Wilcoxon signed-rank</td>\n",
       "      <td>2.971047e-21</td>\n",
       "      <td>7.169704e-09</td>\n",
       "      <td>0.319161</td>\n",
       "      <td>0.121424</td>\n",
       "      <td>0.197737</td>\n",
       "      <td>1.075456e-07</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pmr</td>\n",
       "      <td>baseline vs symspell</td>\n",
       "      <td>Wilcoxon signed-rank</td>\n",
       "      <td>2.205307e-12</td>\n",
       "      <td>1.591306e-06</td>\n",
       "      <td>0.172997</td>\n",
       "      <td>0.391989</td>\n",
       "      <td>0.218992</td>\n",
       "      <td>9.547836e-06</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bleu</td>\n",
       "      <td>baseline vs symspell</td>\n",
       "      <td>Wilcoxon signed-rank</td>\n",
       "      <td>1.098987e-15</td>\n",
       "      <td>4.389483e-04</td>\n",
       "      <td>0.796237</td>\n",
       "      <td>0.804493</td>\n",
       "      <td>0.008257</td>\n",
       "      <td>1.316845e-03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cosine</td>\n",
       "      <td>baseline vs symspell</td>\n",
       "      <td>Wilcoxon signed-rank</td>\n",
       "      <td>1.065112e-17</td>\n",
       "      <td>5.249423e-03</td>\n",
       "      <td>0.883098</td>\n",
       "      <td>0.863786</td>\n",
       "      <td>-0.019312</td>\n",
       "      <td>5.249423e-03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>jw</td>\n",
       "      <td>baseline vs symspell</td>\n",
       "      <td>Wilcoxon signed-rank</td>\n",
       "      <td>1.181378e-09</td>\n",
       "      <td>8.345072e-07</td>\n",
       "      <td>0.846417</td>\n",
       "      <td>0.879365</td>\n",
       "      <td>0.032948</td>\n",
       "      <td>5.841550e-06</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>indobert_P</td>\n",
       "      <td>baseline vs symspell</td>\n",
       "      <td>Wilcoxon signed-rank</td>\n",
       "      <td>2.554037e-14</td>\n",
       "      <td>7.958557e-08</td>\n",
       "      <td>0.918677</td>\n",
       "      <td>0.935379</td>\n",
       "      <td>0.016702</td>\n",
       "      <td>9.550269e-07</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>indobert_R</td>\n",
       "      <td>baseline vs symspell</td>\n",
       "      <td>Wilcoxon signed-rank</td>\n",
       "      <td>1.570122e-16</td>\n",
       "      <td>1.806552e-03</td>\n",
       "      <td>0.937881</td>\n",
       "      <td>0.931343</td>\n",
       "      <td>-0.006538</td>\n",
       "      <td>3.613105e-03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>indobert_F1</td>\n",
       "      <td>baseline vs symspell</td>\n",
       "      <td>Wilcoxon signed-rank</td>\n",
       "      <td>9.618179e-16</td>\n",
       "      <td>6.827915e-06</td>\n",
       "      <td>0.927779</td>\n",
       "      <td>0.932791</td>\n",
       "      <td>0.005012</td>\n",
       "      <td>2.731166e-05</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         metric            comparison                  test     shapiro_p  \\\n",
       "0           wer  baseline vs symspell  Wilcoxon signed-rank  1.830843e-21   \n",
       "2           cer  baseline vs symspell  Wilcoxon signed-rank  2.971047e-21   \n",
       "4           pmr  baseline vs symspell  Wilcoxon signed-rank  2.205307e-12   \n",
       "6          bleu  baseline vs symspell  Wilcoxon signed-rank  1.098987e-15   \n",
       "8        cosine  baseline vs symspell  Wilcoxon signed-rank  1.065112e-17   \n",
       "10           jw  baseline vs symspell  Wilcoxon signed-rank  1.181378e-09   \n",
       "12   indobert_P  baseline vs symspell  Wilcoxon signed-rank  2.554037e-14   \n",
       "14   indobert_R  baseline vs symspell  Wilcoxon signed-rank  1.570122e-16   \n",
       "16  indobert_F1  baseline vs symspell  Wilcoxon signed-rank  9.618179e-16   \n",
       "\n",
       "         p_value  mean_baseline  mean_refined  mean_improvement   p_corrected  \\\n",
       "0   1.189345e-08       0.432745      0.172637          0.260108  1.665083e-07   \n",
       "2   7.169704e-09       0.319161      0.121424          0.197737  1.075456e-07   \n",
       "4   1.591306e-06       0.172997      0.391989          0.218992  9.547836e-06   \n",
       "6   4.389483e-04       0.796237      0.804493          0.008257  1.316845e-03   \n",
       "8   5.249423e-03       0.883098      0.863786         -0.019312  5.249423e-03   \n",
       "10  8.345072e-07       0.846417      0.879365          0.032948  5.841550e-06   \n",
       "12  7.958557e-08       0.918677      0.935379          0.016702  9.550269e-07   \n",
       "14  1.806552e-03       0.937881      0.931343         -0.006538  3.613105e-03   \n",
       "16  6.827915e-06       0.927779      0.932791          0.005012  2.731166e-05   \n",
       "\n",
       "    significant  \n",
       "0          True  \n",
       "2          True  \n",
       "4          True  \n",
       "6          True  \n",
       "8          True  \n",
       "10         True  \n",
       "12         True  \n",
       "14         True  \n",
       "16         True  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[results_df['comparison'] == 'baseline vs symspell']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
