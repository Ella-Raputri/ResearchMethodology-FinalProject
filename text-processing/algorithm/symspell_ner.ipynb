{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b70ceb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\miniconda3\\envs\\yolo-env1\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from symspellpy import SymSpell, Verbosity\n",
    "from transformers import pipeline\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbb8af90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from wordfreq import top_n_list\n",
    "english_vocab = set(top_n_list(\"en\", 50000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e2aba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50156267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym_spell = SymSpell()\n",
    "sym_spell.load_pickle(\"../../data/dictionary/symspell_dictionary.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f57e7820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpora = [\n",
    "#     \"../data/dictionary/dataset_wot_uncased_blanklines/processed_uncased_blanklines/wiki.txt\",\n",
    "#     \"../data/dictionary/dataset_wot_uncased_blanklines/processed_uncased_blanklines/kompas.txt\",\n",
    "#     \"../data/dictionary/dataset_wot_uncased_blanklines/processed_uncased_blanklines/tempo.txt\",\n",
    "#     \"../data/dictionary/dataset_wot_uncased_blanklines/processed_uncased_blanklines/bppt.txt\"\n",
    "# ]\n",
    "\n",
    "# for corpus in corpora:\n",
    "#     sym_spell.create_dictionary(corpus)\n",
    "\n",
    "# if \"jumal\" in sym_spell.words:\n",
    "#     del sym_spell.words[\"jumal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "509a96e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# addon_path = \"../../data/dictionary/addon.txt\"\n",
    "\n",
    "# with open(addon_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#     words = [w.strip() for w in f.readlines() if w.strip()]\n",
    "\n",
    "# for word in words:\n",
    "#     entry = sym_spell.words.get(word)\n",
    "#     current_count = entry if entry is not None else 0\n",
    "#     if current_count < 10:\n",
    "#         sym_spell.create_dictionary_entry(word, 10 - current_count)\n",
    "\n",
    "# sym_spell.save_pickle(\"../../data/dictionary/symspell_dictionary.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd3f359c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "c:\\Users\\Asus\\miniconda3\\envs\\yolo-env1\\Lib\\site-packages\\transformers\\pipelines\\token_classification.py:186: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "ner = pipeline(\"ner\", model=\"cahya/NusaBert-ner-v1.3\", grouped_entities=True)\n",
    "model_name = \"indolem/indobert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab7e40c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_typos(text):\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    typos = defaultdict(list)\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        words = re.findall(r\"\\b[a-zA-Z]+\\b\", sentence.lower())\n",
    "        # print(words)\n",
    "        \n",
    "        for word in words:\n",
    "            if word in english_vocab or len(word) <= 2:\n",
    "                continue\n",
    "            \n",
    "            # print(word)\n",
    "            suggestions = sym_spell.lookup(word, Verbosity.CLOSEST, max_edit_distance=2, include_unknown=True)\n",
    "            best = suggestions[0]\n",
    "            \n",
    "            if (best.term != word and best.distance > 0) or (best.count < 10):\n",
    "                if sentence.strip() not in typos[word]:  \n",
    "                    typos[word].append(sentence.strip())\n",
    "\n",
    "    return typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2264b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_correct(entity_label, suggestion):\n",
    "    if entity_label in {\"PERSON\", \"GPE\", \"LOC\"}:\n",
    "        return False\n",
    "\n",
    "    if entity_label == \"ORG\":\n",
    "        if suggestion in sym_spell.words:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    if entity_label is None:\n",
    "        return suggestion in sym_spell.words\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "611ce949",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_confusions = {\n",
    "    'rn': ['m'],\n",
    "    'm': ['rn'],\n",
    "    'l': ['t', 'i'],\n",
    "    't': ['l'],\n",
    "    '0': ['o'],\n",
    "    '1': ['l', 'i'],\n",
    "    'o': ['0'],\n",
    "    'n': ['ri', 'ni'],\n",
    "    'vv': ['w'],\n",
    "    'w': ['vv'],\n",
    "    'e':['c']\n",
    "}\n",
    "\n",
    "def expand_ocr_variants(word):\n",
    "    variants = set()\n",
    "    for pattern, subs in ocr_confusions.items():\n",
    "        if pattern in word:\n",
    "            for s in subs:\n",
    "                variants.add(re.sub(pattern, s, word))\n",
    "    return variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d6d2a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_words(word):\n",
    "    suggest_symspell = sym_spell.lookup(word, Verbosity.CLOSEST, max_edit_distance=2, include_unknown=True)\n",
    "    \n",
    "    valid_suggestions = [s for s in suggest_symspell if s.count > 10]\n",
    "    if valid_suggestions: best = valid_suggestions[0].term\n",
    "    else: best = suggest_symspell[0].term\n",
    "\n",
    "    variants = expand_ocr_variants(word)\n",
    "\n",
    "    final_s = set()\n",
    "    final_s.add(best)\n",
    "\n",
    "    for var in variants:\n",
    "        if var in sym_spell.words:\n",
    "            final_s.add(var)\n",
    "    return final_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6635743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_highest(model, tokenizer, sentence, cands, word):\n",
    "    sentence = sentence.lower()\n",
    "    window = 500\n",
    "\n",
    "    if (len(sentence) >= window*2): \n",
    "        idx = sentence.find(word)\n",
    "        start = max(0, idx - window)\n",
    "        end = min(len(sentence), idx + len(word) + window)\n",
    "        sentence = sentence[start:end]\n",
    "\n",
    "    sentence = sentence.replace(word,'[MASK]')\n",
    "\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "    \n",
    "    mask_token_id = tokenizer.mask_token_id\n",
    "    mask_token_index = (inputs.input_ids == mask_token_id).nonzero(as_tuple=True)[1]\n",
    "    mask_logits = logits[0, mask_token_index, :]\n",
    "\n",
    "    candidate_ids = tokenizer.convert_tokens_to_ids(cands)\n",
    "    candidate_scores = mask_logits[0, candidate_ids]\n",
    "    \n",
    "    best_candidate_index = candidate_scores.argmax().item()\n",
    "    best_candidate = cands[best_candidate_index]\n",
    "    return best_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95104420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_correct(typos):\n",
    "    corrections = []\n",
    "\n",
    "    for word, sentences in tqdm(typos.items(), desc='Processing words'):\n",
    "        for sentence in sentences:\n",
    "            doc = ner(sentence)\n",
    "            entity_label = None\n",
    "\n",
    "            # cari entity label kata typo\n",
    "            for ent in doc:\n",
    "                if word.lower() in ent[\"word\"].lower():\n",
    "                    entity_label = ent[\"entity_group\"]\n",
    "                    break\n",
    "            \n",
    "            suggestions = suggest_words(word)\n",
    "            if not suggestions:\n",
    "                continue #kalau gada suggestions\n",
    "\n",
    "            best_word = output_highest(model, tokenizer, sentence, list(suggestions), word)\n",
    "            if(not should_correct(entity_label, best_word)): continue\n",
    "            corrections.append({\"word\":word, \"correction\":best_word})\n",
    "            \n",
    "    return corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e0f848e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing words: 100%|██████████| 131/131 [01:53<00:00,  1.16it/s]\n",
      "Processing words: 100%|██████████| 4/4 [00:02<00:00,  1.68it/s]it]\n",
      "Processing words: 100%|██████████| 10/10 [00:05<00:00,  1.96it/s] \n",
      "Processing words: 100%|██████████| 8/8 [00:02<00:00,  2.76it/s]t]\n",
      "Processing words: 100%|██████████| 12/12 [00:04<00:00,  2.65it/s]\n",
      "Processing words: 100%|██████████| 42/42 [00:05<00:00,  7.27it/s]\n",
      "Processing words: 100%|██████████| 15/15 [00:01<00:00,  7.65it/s]\n",
      "Processing words: 0it [00:00, ?it/s]83 [02:16<23:18,  7.94s/it]\n",
      "Processing words: 100%|██████████| 22/22 [00:08<00:00,  2.73it/s]\n",
      "Processing words: 100%|██████████| 18/18 [00:02<00:00,  6.46it/s]\n",
      "Processing words: 100%|██████████| 25/25 [00:05<00:00,  4.82it/s]\n",
      "Processing words: 100%|██████████| 18/18 [00:14<00:00,  1.28it/s]\n",
      "Processing words: 100%|██████████| 30/30 [00:10<00:00,  2.88it/s]\n",
      "Processing words: 100%|██████████| 32/32 [00:09<00:00,  3.42it/s]\n",
      "Processing words: 100%|██████████| 45/45 [00:06<00:00,  6.73it/s]\n",
      "Processing words: 100%|██████████| 52/52 [00:06<00:00,  8.15it/s]\n",
      "Processing words: 100%|██████████| 46/46 [00:06<00:00,  7.63it/s]\n",
      "Processing words: 100%|██████████| 7/7 [00:00<00:00,  7.13it/s]]\n",
      "Processing words: 100%|██████████| 4/4 [00:00<00:00,  4.74it/s]]\n",
      "Processing words: 100%|██████████| 4/4 [00:00<00:00,  5.95it/s]]\n",
      "Processing words: 100%|██████████| 5/5 [00:01<00:00,  4.32it/s]]\n",
      "Processing words: 100%|██████████| 5/5 [00:01<00:00,  4.30it/s]]\n",
      "Processing words: 100%|██████████| 7/7 [00:01<00:00,  3.83it/s]]\n",
      "Processing words: 100%|██████████| 2/2 [00:00<00:00,  4.43it/s]]\n",
      "Processing words: 100%|██████████| 6/6 [00:01<00:00,  5.38it/s]]\n",
      "Processing words: 100%|██████████| 6/6 [00:01<00:00,  5.01it/s]]\n",
      "Processing words: 100%|██████████| 3/3 [00:00<00:00,  4.96it/s]]\n",
      "Processing words: 100%|██████████| 10/10 [00:01<00:00,  5.83it/s]\n",
      "Processing words: 100%|██████████| 4/4 [00:00<00:00,  5.89it/s]]\n",
      "Processing words: 100%|██████████| 1/1 [00:00<00:00,  4.09it/s]]\n",
      "Processing words: 0it [00:00, ?it/s]183 [03:38<02:13,  1.14it/s]\n",
      "Processing words: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s]\n",
      "Processing words: 100%|██████████| 2/2 [00:00<00:00,  4.39it/s]]\n",
      "Processing words: 100%|██████████| 2/2 [00:00<00:00,  8.70it/s]]\n",
      "Processing words: 100%|██████████| 1/1 [00:00<00:00,  8.57it/s]]\n",
      "Processing words: 0it [00:00, ?it/s]183 [03:39<00:53,  2.77it/s]\n",
      "Processing words: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s]\n",
      "Processing words: 100%|██████████| 2/2 [00:00<00:00,  8.17it/s]]\n",
      "Processing words: 100%|██████████| 2/2 [00:00<00:00,  7.81it/s]]\n",
      "Processing words: 100%|██████████| 6/6 [00:01<00:00,  5.19it/s]]\n",
      "Processing words: 100%|██████████| 2/2 [00:00<00:00,  8.23it/s]]\n",
      "Processing words: 100%|██████████| 2/2 [00:00<00:00,  8.53it/s]]\n",
      "Processing words: 100%|██████████| 4/4 [00:00<00:00,  7.30it/s]]\n",
      "Processing words: 100%|██████████| 5/5 [00:00<00:00,  7.39it/s]]\n",
      "Processing words: 100%|██████████| 6/6 [00:01<00:00,  5.40it/s]]\n",
      "Processing words: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s]]\n",
      "Processing words: 100%|██████████| 24/24 [00:07<00:00,  3.39it/s]\n",
      "Processing words: 100%|██████████| 5/5 [00:01<00:00,  4.46it/s]]\n",
      "Processing words: 100%|██████████| 4/4 [00:00<00:00,  5.36it/s]]\n",
      "Processing words: 100%|██████████| 19/19 [00:04<00:00,  4.53it/s]\n",
      "Processing words: 100%|██████████| 1/1 [00:00<00:00,  4.18it/s]]\n",
      "Processing words: 100%|██████████| 3/3 [00:00<00:00,  6.73it/s]]\n",
      "Processing words: 100%|██████████| 2/2 [00:00<00:00,  6.30it/s]]\n",
      "Processing words: 100%|██████████| 2/2 [00:00<00:00,  5.71it/s]]\n",
      "Processing words: 100%|██████████| 3/3 [00:00<00:00,  6.38it/s]]\n",
      "Processing words: 100%|██████████| 6/6 [00:01<00:00,  5.29it/s]]\n",
      "Processing words: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s]]\n",
      "Processing words: 100%|██████████| 6/6 [00:01<00:00,  4.88it/s]]\n",
      "Processing words: 100%|██████████| 1/1 [00:00<00:00,  2.12it/s]]\n",
      "Processing words: 100%|██████████| 6/6 [00:01<00:00,  3.66it/s]]\n",
      "Processing words: 100%|██████████| 2/2 [00:00<00:00,  5.05it/s]]\n",
      "Processing words: 100%|██████████| 4/4 [00:00<00:00,  6.12it/s]]\n",
      "Processing words: 100%|██████████| 15/15 [00:02<00:00,  5.50it/s]\n",
      "Processing words: 100%|██████████| 19/19 [00:04<00:00,  3.91it/s]\n",
      "Processing words: 100%|██████████| 9/9 [00:01<00:00,  7.30it/s]]\n",
      "Processing words: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s]]\n",
      "Processing words: 0it [00:00, ?it/s]183 [04:15<02:57,  1.52s/it]\n",
      "Processing words: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s]\n",
      "Processing words: 100%|██████████| 2/2 [00:00<00:00,  5.51it/s]]\n",
      "Processing words: 100%|██████████| 2/2 [00:00<00:00,  7.82it/s]]\n",
      "Processing words: 100%|██████████| 5/5 [00:00<00:00,  7.00it/s]]\n",
      "Processing words: 100%|██████████| 4/4 [00:00<00:00,  8.06it/s]]\n",
      "Processing words: 100%|██████████| 7/7 [00:01<00:00,  6.78it/s]]\n",
      "Processing words: 100%|██████████| 3/3 [00:00<00:00,  7.76it/s]]\n",
      "Processing words: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s]]\n",
      "Processing words: 100%|██████████| 6/6 [00:01<00:00,  5.57it/s]]\n",
      "Processing words: 100%|██████████| 3/3 [00:00<00:00,  5.20it/s]]\n",
      "Processing words: 100%|██████████| 3/3 [00:00<00:00,  3.41it/s]]\n",
      "Processing words: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s]]\n",
      "Processing words: 100%|██████████| 7/7 [00:01<00:00,  6.78it/s]]\n",
      "Processing words: 100%|██████████| 3/3 [00:00<00:00,  4.60it/s]]\n",
      "Processing words: 100%|██████████| 3/3 [00:00<00:00,  4.85it/s]]\n",
      "Processing words: 100%|██████████| 6/6 [00:00<00:00,  7.39it/s]]\n",
      "Processing words: 100%|██████████| 4/4 [00:01<00:00,  3.43it/s]]\n",
      "Processing words: 100%|██████████| 4/4 [00:01<00:00,  3.50it/s]]\n",
      "Processing words: 100%|██████████| 3/3 [00:00<00:00,  7.19it/s]]\n",
      "Processing words: 100%|██████████| 8/8 [00:01<00:00,  4.90it/s]]\n",
      "Processing words: 100%|██████████| 4/4 [00:00<00:00,  5.43it/s]]\n",
      "Processing words: 100%|██████████| 5/5 [00:00<00:00,  6.27it/s]]\n",
      "Processing words: 100%|██████████| 6/6 [00:01<00:00,  4.62it/s]]\n",
      "Processing words: 100%|██████████| 8/8 [00:01<00:00,  5.24it/s]]\n",
      "Processing words: 100%|██████████| 5/5 [00:00<00:00,  7.94it/s]]\n",
      "Processing words: 100%|██████████| 5/5 [00:00<00:00,  7.81it/s]]\n",
      "Processing words: 100%|██████████| 3/3 [00:00<00:00,  9.20it/s]]\n",
      "Processing words: 100%|██████████| 4/4 [00:00<00:00,  6.22it/s]]\n",
      "Processing words: 100%|██████████| 7/7 [00:00<00:00,  7.83it/s]]\n",
      "Processing words: 100%|██████████| 5/5 [00:00<00:00,  8.13it/s]]\n",
      "Processing words: 100%|██████████| 11/11 [00:02<00:00,  4.28it/s]\n",
      "Processing words: 100%|██████████| 13/13 [00:02<00:00,  5.13it/s]\n",
      "Processing words: 100%|██████████| 2/2 [00:00<00:00,  7.44it/s]]\n",
      "Processing words: 100%|██████████| 6/6 [00:01<00:00,  4.76it/s]t]\n",
      "Processing words: 100%|██████████| 2/2 [00:00<00:00,  7.67it/s]t]\n",
      "Processing words: 100%|██████████| 3/3 [00:00<00:00,  6.18it/s]s]\n",
      "Processing words: 100%|██████████| 7/7 [00:01<00:00,  5.60it/s]s]\n",
      "Processing words: 100%|██████████| 2/2 [00:00<00:00,  6.75it/s]s]\n",
      "Processing words: 100%|██████████| 4/4 [00:00<00:00,  6.26it/s]s]\n",
      "Processing words: 100%|██████████| 5/5 [00:00<00:00,  8.05it/s]s]\n",
      "Processing words: 100%|██████████| 6/6 [00:00<00:00,  8.00it/s]s]\n",
      "Processing words: 100%|██████████| 13/13 [00:02<00:00,  6.43it/s]\n",
      "Processing words: 100%|██████████| 12/12 [00:01<00:00,  6.22it/s]\n",
      "Processing words: 100%|██████████| 5/5 [00:00<00:00,  7.32it/s]t]\n",
      "Processing words: 100%|██████████| 4/4 [00:00<00:00,  7.82it/s]t]\n",
      "Processing words: 100%|██████████| 10/10 [00:01<00:00,  6.55it/s]\n",
      "Processing words: 100%|██████████| 9/9 [00:01<00:00,  6.18it/s]t]\n",
      "Processing words: 100%|██████████| 14/14 [00:02<00:00,  6.25it/s]\n",
      "Processing words: 100%|██████████| 5/5 [00:01<00:00,  4.87it/s]t]\n",
      "Processing words: 100%|██████████| 11/11 [00:01<00:00,  6.06it/s]\n",
      "Processing words: 100%|██████████| 9/9 [00:01<00:00,  4.79it/s]t]\n",
      "Processing words: 100%|██████████| 6/6 [00:00<00:00,  6.82it/s]t]\n",
      "Processing words: 100%|██████████| 4/4 [00:00<00:00,  7.44it/s]t]\n",
      "Processing words: 0it [00:00, ?it/s]/183 [05:05<01:13,  1.17s/it]\n",
      "Processing words: 100%|██████████| 13/13 [00:03<00:00,  4.33it/s]\n",
      "Processing words: 100%|██████████| 3/3 [00:00<00:00,  7.09it/s]t]\n",
      "Processing words: 100%|██████████| 2/2 [00:00<00:00,  6.54it/s]t]\n",
      "Processing words: 100%|██████████| 10/10 [00:01<00:00,  6.28it/s]\n",
      "Processing words: 100%|██████████| 3/3 [00:01<00:00,  2.98it/s]t]\n",
      "Processing words: 100%|██████████| 4/4 [00:00<00:00,  7.36it/s]t]\n",
      "Processing words: 100%|██████████| 5/5 [00:00<00:00,  5.52it/s]s]\n",
      "Processing words: 100%|██████████| 8/8 [00:01<00:00,  4.40it/s]s]\n",
      "Processing words: 100%|██████████| 9/9 [00:01<00:00,  7.11it/s]t]\n",
      "Processing words: 100%|██████████| 10/10 [00:01<00:00,  5.48it/s]\n",
      "Processing words: 100%|██████████| 7/7 [00:00<00:00,  7.09it/s]t]\n",
      "Processing words: 100%|██████████| 14/14 [00:02<00:00,  5.81it/s]\n",
      "Processing words: 100%|██████████| 8/8 [00:01<00:00,  6.92it/s]t]\n",
      "Processing words: 100%|██████████| 8/8 [00:01<00:00,  5.46it/s]t]\n",
      "Processing words: 100%|██████████| 7/7 [00:01<00:00,  5.31it/s]t]\n",
      "Processing words: 100%|██████████| 4/4 [00:00<00:00,  8.06it/s]t]\n",
      "Processing words: 100%|██████████| 6/6 [00:01<00:00,  3.86it/s]t]\n",
      "Processing words: 100%|██████████| 6/6 [00:00<00:00,  7.14it/s]t]\n",
      "Processing words: 100%|██████████| 5/5 [00:00<00:00,  8.00it/s]t]\n",
      "Processing words: 100%|██████████| 12/12 [00:01<00:00,  7.12it/s]\n",
      "Processing words: 100%|██████████| 4/4 [00:00<00:00,  6.47it/s]t]\n",
      "Processing words: 100%|██████████| 13/13 [00:01<00:00,  6.50it/s]\n",
      "Processing words: 100%|██████████| 10/10 [00:01<00:00,  6.65it/s]\n",
      "Processing words: 100%|██████████| 10/10 [00:02<00:00,  4.47it/s]\n",
      "Processing words: 100%|██████████| 13/13 [00:01<00:00,  6.60it/s]\n",
      "Processing words: 100%|██████████| 10/10 [00:01<00:00,  8.72it/s]\n",
      "Processing words: 100%|██████████| 2/2 [00:00<00:00,  7.76it/s]t]\n",
      "Processing words: 100%|██████████| 5/5 [00:00<00:00,  7.45it/s]t]\n",
      "Processing words: 100%|██████████| 6/6 [00:01<00:00,  5.06it/s]t]\n",
      "Processing words: 100%|██████████| 3/3 [00:00<00:00,  7.14it/s]t]\n",
      "Processing words: 100%|██████████| 7/7 [00:01<00:00,  6.78it/s]s]\n",
      "Processing words: 100%|██████████| 10/10 [00:01<00:00,  5.09it/s]\n",
      "Processing words: 100%|██████████| 9/9 [00:01<00:00,  6.88it/s]t]\n",
      "Processing words: 100%|██████████| 5/5 [00:00<00:00,  5.96it/s]t]\n",
      "Processing words: 100%|██████████| 10/10 [00:01<00:00,  6.32it/s]\n",
      "Processing words: 100%|██████████| 11/11 [00:01<00:00,  6.78it/s]\n",
      "Processing words: 100%|██████████| 22/22 [00:03<00:00,  6.90it/s]\n",
      "Processing words: 100%|██████████| 9/9 [00:01<00:00,  5.88it/s]t]\n",
      "Processing words: 100%|██████████| 30/30 [00:05<00:00,  5.32it/s]\n",
      "Processing words: 100%|██████████| 19/19 [00:02<00:00,  6.95it/s]\n",
      "Processing words: 100%|██████████| 18/18 [00:03<00:00,  4.60it/s]\n",
      "Processing words: 100%|██████████| 6/6 [00:01<00:00,  3.73it/s]t]\n",
      "Processing words: 100%|██████████| 11/11 [00:01<00:00,  6.03it/s]\n",
      "Processing words: 100%|██████████| 21/21 [00:03<00:00,  5.71it/s]\n",
      "Processing words: 100%|██████████| 6/6 [00:00<00:00,  6.27it/s]t]\n",
      "Processing words: 100%|██████████| 9/9 [00:01<00:00,  5.84it/s]t]\n",
      "Processing words: 100%|██████████| 18/18 [00:02<00:00,  6.27it/s]\n",
      "Processing words: 100%|██████████| 14/14 [00:02<00:00,  6.19it/s]\n",
      "Processing words: 100%|██████████| 12/12 [00:02<00:00,  5.42it/s]\n",
      "Processing words: 100%|██████████| 9/9 [00:02<00:00,  3.64it/s]t]\n",
      "Processing words: 100%|██████████| 4/4 [00:00<00:00,  7.70it/s]t]\n",
      "Processing words: 100%|██████████| 3/3 [00:00<00:00,  7.67it/s]t]\n",
      "Processing words: 100%|██████████| 3/3 [00:00<00:00,  4.41it/s]t]\n",
      "Processing words: 100%|██████████| 3/3 [00:00<00:00,  5.93it/s]t]\n",
      "Processing words: 100%|██████████| 4/4 [00:00<00:00,  7.52it/s]s]\n",
      "Processing words: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s]s]\n",
      "Processing words: 100%|██████████| 4/4 [00:00<00:00,  6.44it/s]s]\n",
      "Processing words: 100%|██████████| 1/1 [00:00<00:00,  3.18it/s]s]\n",
      "Processing words: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s]s]\n",
      "Processing words: 100%|██████████| 3/3 [00:00<00:00,  3.54it/s]s]\n",
      "Processing words: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s]s]\n",
      "Processing words: 100%|██████████| 11/11 [00:02<00:00,  5.48it/s]\n",
      "Iterating data: 100%|██████████| 183/183 [06:36<00:00,  2.17s/it]\n"
     ]
    }
   ],
   "source": [
    "start, n = 479, 662\n",
    "\n",
    "for i in tqdm(range(start, n), desc='Iterating data'):\n",
    "    with open(f\"../../data/raw/ocr_result/ocr_{i}.txt\", 'r', encoding=\"utf-8\", errors=\"ignore\") as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    typos = find_typos(text)\n",
    "    res = context_correct(typos)\n",
    "    corrected_text = text\n",
    "    for obj in res:\n",
    "        wrong = re.escape(obj['word'])\n",
    "        corr = obj['correction']\n",
    "        corrected_text = re.sub(rf\"\\b{wrong}\\b\", corr, corrected_text, flags=re.IGNORECASE)\n",
    "    \n",
    "    with open(f\"./symspell_res/res_{i}.txt\", \"w\",encoding=\"utf-8\", errors=\"ignore\") as file:\n",
    "        file.write(corrected_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo-env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
