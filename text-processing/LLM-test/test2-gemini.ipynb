{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c05bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.genai import types\n",
    "from google import genai\n",
    "import re, os, json\n",
    "from jiwer import wer, cer\n",
    "from dotenv import load_dotenv\n",
    "from rapidfuzz import process\n",
    "from scipy.stats import kendalltau\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "# print(API_KEY)\n",
    "\n",
    "client = genai.Client(\n",
    "    api_key=API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51d8d554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 187\n"
     ]
    }
   ],
   "source": [
    "with open('../../evaluation/eval_list.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "eval_list = []\n",
    "for img_name in content.split('\\n'):\n",
    "    eval_list.append(img_name.split('.')[0])\n",
    "\n",
    "eval_list = eval_list[83:]\n",
    "print(len(eval_list), eval_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "236143da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['187', '615', '1', '295', '244', '286', '8', '120', '5', '586', '177', '47', '471', '494', '658', '535', '450']\n"
     ]
    }
   ],
   "source": [
    "print(eval_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb821973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 ../data/raw/ocr_result/ocr_187.txt ../data/raw/ocr_result/ocr_450.txt\n",
      "17 ../data/raw/ground_truth/ocr_187.txt ../data/raw/ground_truth/ocr_450.txt\n"
     ]
    }
   ],
   "source": [
    "start = 424\n",
    "n = 425\n",
    "text_list = [f'../data/raw/ocr_result/ocr_{x}.txt' for x in eval_list]\n",
    "print(len(text_list), text_list[0], text_list[-1])\n",
    "\n",
    "gt_list = [f'../data/raw/ground_truth/ocr_{x}.txt' for x in eval_list]\n",
    "print(len(gt_list), gt_list[0], gt_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "406a992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_prompt(row):\n",
    "    prompt = (\n",
    "        \"Teks berikut adalah hasil OCR:\\n\\n\"\n",
    "        f\"{row}\\n\\n\"\n",
    "        \"Instruksi:\\n\"\n",
    "        \"1. Jangan susun ulang teks.\\n\"\n",
    "        \"2. Perbaiki typo dan kesalahan yang penyebabnya adalah OCR.\\n\"\n",
    "        \"3. Jangan menambah, mengurangi, atau mengubah informasi apa pun.\\n\"\n",
    "        \"4. Jangan menambah komentar, penjelasan, atau catatan.\\n\"\n",
    "        \"5. Output harus berupa teks final saja, tanpa markdown, tanpa format tambahan.\\n\"\n",
    "        \"6. Jangan melakukan asumsi atau mengisi bagian teks yang hilang.\\n\"\n",
    "        \"7. Teks output **harus berisi kata-kata yang sama dengan input**, kecuali kata yang memang diperbaiki karena typo.\\n\"\n",
    "        \"8. Jangan mengubah struktur kalimat secara berlebihan—hanya perbaiki ejaan.\\n\\n\"\n",
    "        \"PERINTAH PENTING:\\n\"\n",
    "        \"• Jangan membuat kalimat baru.\\n\"\n",
    "        \"• Jangan menghilangkan kata.\\n\"\n",
    "        \"• Jangan melakukan halusinasi.\\n\"\n",
    "        \"• Kembalikan hanya teks yang sudah diperbaiki.\"\n",
    "    )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5bf8f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = []\n",
    "trained = []\n",
    "\n",
    "def pmr(gt, pred):\n",
    "    gt_words = gt.split()\n",
    "    pred_words = pred.split()\n",
    "    length = min(len(gt_words), len(pred_words))\n",
    "    matches = sum(1 for i in range(length) if gt_words[i] == pred_words[i])\n",
    "    return matches / length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "132ec4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Correcting typos:  35%|███▌      | 6/17 [02:05<03:35, 19.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row - Error processing column : 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'Visibility check was unavailable. Please retry the request and contact support if the problem persists', 'status': 'UNAVAILABLE'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Correcting typos: 100%|██████████| 17/17 [06:01<00:00, 21.24s/it]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "for index in tqdm(eval_list, desc='Correcting typos'):\n",
    "    time.sleep(5)\n",
    "    row = \"\"\n",
    "    with open(f\"../../yolo/yolo_res/res_{index}.txt\", \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n",
    "        row = file.read()\n",
    "\n",
    "    try:\n",
    "        model = \"gemini-2.5-flash\"\n",
    "        contents = [\n",
    "            types.Content(\n",
    "                role=\"user\",\n",
    "                parts=[\n",
    "                    types.Part.from_text(text=return_prompt(row)),\n",
    "                ],\n",
    "            ),\n",
    "        ]\n",
    "        generate_content_config = types.GenerateContentConfig(\n",
    "            response_mime_type=\"text/plain\",\n",
    "        )\n",
    "\n",
    "        response_text=\"\"\n",
    "        for chunk in client.models.generate_content_stream(\n",
    "            model=model,\n",
    "            contents=contents,\n",
    "            config=generate_content_config,\n",
    "        ): response_text += chunk.text\n",
    "\n",
    "        # print(index)\n",
    "        # print(response_text)\n",
    "        \n",
    "        with open(f\"./final_LLM_res/res_{index}.txt\", \"w\",encoding=\"utf-8\", errors=\"ignore\") as file:\n",
    "            file.write(response_text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Row - Error processing column :\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7ce24c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate(gt, row, True)\n",
    "# evaluate(gt, response_text, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ed0b65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"eval_baseline.txt\", \"a\") as file:\n",
    "#     file.write(str(baseline))\n",
    "# with open(\"eval_trained.txt\", \"a\") as file:\n",
    "#     file.write(str(trained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65380779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71451822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(trained)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
