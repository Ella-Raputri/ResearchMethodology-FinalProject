{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0c05bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyCOe__7cUEoi0X7cCe8NkqJMQkVrxA1sNo\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from google.genai import types\n",
    "from google import genai\n",
    "import re, os, json\n",
    "from jiwer import wer, cer\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "print(API_KEY)\n",
    "\n",
    "client = genai.Client(\n",
    "    api_key=API_KEY\n",
    ")\n",
    "\n",
    "\n",
    "row = \"\"\n",
    "with open(\"D:/ResearchMethodology-FinalProject/data/raw/ocr_result/ocr_48.txt\", \"r\") as file:\n",
    "    row = file.read()\n",
    "\n",
    "gt = \"\"\n",
    "with open(\"D:/ResearchMethodology-FinalProject/data/raw/ground_truth/gt_48.txt\", \"r\") as file:\n",
    "    gt = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "132ec4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fhir_rows = []\n",
    "\n",
    "prompt = (\n",
    "    \"Teks berikut adalah hasil OCR:\\n\\n\"\n",
    "    f\"{row}\\n\\n\"\n",
    "    \"Instruksi:\\n\"\n",
    "    \"1. Susun ulang teks agar urut dan mudah dibaca.\\n\"\n",
    "    \"2. Perbaiki typo dan kesalahan pemenggalan kata.\\n\"\n",
    "    \"3. Jangan menambah, mengurangi, atau mengubah informasi apa pun.\\n\"\n",
    "    \"4. Jangan menambah komentar, penjelasan, atau catatan.\\n\"\n",
    "    \"5. Output harus berupa teks final saja, tanpa markdown, tanpa format tambahan.\\n\"\n",
    "    \"6. Jangan melakukan asumsi atau mengisi bagian teks yang hilang.\\n\"\n",
    "    \"7. Teks output **harus berisi kata-kata yang sama dengan input**, kecuali kata yang memang diperbaiki karena typo.\\n\"\n",
    "    \"8. Jangan mengubah struktur kalimat secara berlebihan—hanya rapikan urutan dan perbaiki ejaan.\\n\\n\"\n",
    "    \"PERINTAH PENTING:\\n\"\n",
    "    \"• Jangan membuat kalimat baru.\\n\"\n",
    "    \"• Jangan menghilangkan kata.\\n\"\n",
    "    \"• Jangan melakukan halusinasi.\\n\"\n",
    "    \"• Kembalikan hanya teks yang sudah diperbaiki.\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    model = \"gemini-2.0-flash\"\n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[\n",
    "                types.Part.from_text(text=prompt),\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "        response_mime_type=\"text/plain\",\n",
    "    )\n",
    "\n",
    "    response_text=\"\"\n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model=model,\n",
    "        contents=contents,\n",
    "        config=generate_content_config,\n",
    "    ): response_text += chunk.text\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Row - Error processing column :\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fbaeaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Join (penggabungan). Pada proses ini setiap item dikombinasikan dengan item yang lainnya sampai tidak terbentuk kombinasi lagi.\n",
      "2. Prune (pemangkasan). Pada proses ini, hasil dari item yang telah dikombinasikan tadi lalu dipangkas dengan menggunakan minimum support yang telah ditentukan oleh user.\n",
      "\n",
      "Metode Penemuan Kesenjangan\n",
      "\n",
      "Akhriza dkk, (2017) pada jurnalnya Revealing The Gap Between Skillset Of Student And Evolving Skills Required By The Industry Of Information And Communication Technology dan juga Litecky dkk, (2010) pada jurnalnya Mining Computing Jobs, penelitian ini memiliki kesamaan yaitu mengeksploitasi lowongan kerja yang dibutuhkan industri sebagai acuan perkembangan TIK, namun yang membedakan, pada jurnal Akhriza dkk, memiliki tujuan lain yaitu menemukan kesenjangan antara keterampilan siswa dengan keterampilan yang dibutuhkan pihak industri, sehingga pihak sekolah atau kampus bisa melakukan evaluasi terhadap kurikulum yang ada. Namun penelitian ini menggunakan frequent itemset saja, sehingga hubungan keterkaitan topik satu dengan yang lain belum ditemukan.\n",
      "\n",
      "Son dkk, (2015) pada jurnal yang berjudul Visualization of e-Health Research Topics and Current Trends Using Social Network Analysis [6]. penelitian ini bertujuan untuk secara kritis meninjau topik penelitian utama dan tren internasional e-kesehatan melalui analisis jaringan sosial. Dalam penelitian ini menggunakan pendekatan clustering atau pengelompokan.\n",
      "\n",
      "Penelitian tentang kesenjangan yang dilakukan oleh Akhriza dkk (2017), Litecky dkk, (2010) dan Son dkk (2015) belum mengukur frequent termset atau himpunan kata yang ada di dalam abstrak. Mereka hanya fokus mengukur kesenjangan metode dengan menggunakan frequent itemset dan belum menggunakan Association Rule (AR Mining), padahal association rule dapat mengungkapkan hubungan topik yang satu dengan yang lain.\n",
      "\n",
      "Maka diusulkan penelitian ini bertujuan untuk mengungkapkan kesenjangan tersebut dengan menggunakan Association Rule (AR Mining), dimana kata-kata yang paling sering muncul (frequent termset) di dalam abstrak skripsi dan abstrak riset dieksploitasi. Dari frequent termset yang dikumpulkan, hubungan antara satu kata dengan yang lain ditemukan, untuk kemudian, perbedaan antara topik yang dibahas di dalam skripsi dengan yang\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e754787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 0.2\n",
      "CER: 0.11801980198019801\n"
     ]
    }
   ],
   "source": [
    "wer_baseline2 = wer(gt, response_text)\n",
    "cer_baseline2 = cer(gt, response_text)\n",
    "\n",
    "print(\"WER:\", wer_baseline2)\n",
    "print(\"CER:\", cer_baseline2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8314eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 0.4909090909090909\n",
      "CER: 0.15405940594059406\n"
     ]
    }
   ],
   "source": [
    "wer_baseline2 = wer(gt, row)\n",
    "cer_baseline2 = cer(gt, row)\n",
    "\n",
    "print(\"WER:\", wer_baseline2)\n",
    "print(\"CER:\", cer_baseline2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
